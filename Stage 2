import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, cross_val_score
# -----------------------------
# 1. Load dataset
# -----------------------------
# Dataset: https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength
# Provided file: Concrete_Data.xlsx

#file_path = r"C:\Users\nidhi\Downloads\concrete+compressive+strength\Concrete_Data.xlsx"
df=pd.read_excel("Concrete_Data.xls")

print("Dataset shape:", df.shape)
print(df.head())

# Rename columns for easier handling
df.columns = ['cement', 'slag', 'fly_ash', 'water', 'superplasticizer', 'coarse_agg', 'fine_agg', 'age', 'strength']
df

# Histogram of target variable
plt.hist(df["strength"], bins=30, edgecolor="black")
plt.xlabel("Compressive Strength (MPa)")
plt.ylabel("Frequency")
plt.title("Distribution of Concrete Compressive Strength")
plt.show()

# Correlation heatmap
import seaborn as sns
plt.figure(figsize=(8,6))
#sns.heatmap(df.corr(), annot=False, cmap="coolwarm")
correlation_matrix = df.corr().round(2)
sns.heatmap(data=correlation_matrix, annot = True)
plt.title("Correlation Heatmap of Features")
plt.show()

# -----------------------------
# 3. Features and Target
# -----------------------------
X = df.drop(columns=["strength"])
y = df["strength"]


# -----------------------------
# 4. Train/Test Split
# -----------------------------
X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size=0.2, random_state=42
)


print("Training set size:", X_train.shape[0])
print("Test set size:", X_test.shape[0])


lin_reg = LinearRegression()
cv_rmse_lin = np.sqrt(-cross_val_score(lin_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error'))
lin_reg.fit(X_train, y_train)
y_pred_lin = lin_reg.predict(X_test)

rmse_lin = np.sqrt(mean_squared_error(y_test, y_pred_lin))
r2_lin = r2_score(y_test, y_pred_lin)

print("Linear Regression:")
print(f"  Cross-val RMSE: {cv_rmse_lin.mean():.2f} ± {cv_rmse_lin.std():.2f}")
print(f"  Test RMSE: {rmse_lin:.2f}")
print(f"  Test R²: {r2_lin:.2f}\n")

# -----------------------------
# 5. Second Model: Random Forest Regressor
# -----------------------------
rf_reg = RandomForestRegressor(n_estimators=200, random_state=42)
cv_rmse_rf = np.sqrt(-cross_val_score(rf_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error'))
rf_reg.fit(X_train, y_train)
y_pred_rf = rf_reg.predict(X_test)

rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)

print("Random Forest Regressor:")
print(f"  Cross-val RMSE: {cv_rmse_rf.mean():.2f} ± {cv_rmse_rf.std():.2f}")
print(f"  Test RMSE: {rmse_rf:.2f}")
print(f"  Test R²: {r2_rf:.2f}\n")

# -----------------------------
# 6. Results Summary Table
# -----------------------------
results = pd.DataFrame({
    'Model': ['Linear Regression', 'Random Forest Regressor'],
    'Cross-val RMSE (MPa)': [cv_rmse_lin.mean(), cv_rmse_rf.mean()],
    'Test RMSE (MPa)': [rmse_lin, rmse_rf],
    'R² (Test)': [r2_lin, r2_rf]
})

print("\nPerformance Comparison:")
print(results)

# -----------------------------
# 7. Visualizations
# -----------------------------
plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred_lin, alpha=0.6, label='Linear Regression')
plt.scatter(y_test, y_pred_rf, alpha=0.6, label='Random Forest')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', label='Perfect Prediction')
plt.xlabel('Actual Strength (MPa)')
plt.ylabel('Predicted Strength (MPa)')
plt.title('Predicted vs Actual Compressive Strength')
plt.legend()
plt.show()

# Feature importance for Random Forest
importances = rf_reg.feature_importances_
features = X.columns
importance_df = pd.DataFrame({'Feature': features, 'Importance': importances}).sort_values(by='Importance', ascending=False)

plt.figure(figsize=(8, 5))
sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')
plt.title('Feature Importance - Random Forest Regressor')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

# -----------------------------
# 8. Save summary results
# -----------------------------
results.to_csv("model_comparison_results.csv", index=False)
